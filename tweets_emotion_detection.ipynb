{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion detection from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature_extraction import FeatureExtractionContextValenceShifting\n",
    "from feature_selection import generate_initial_features, feature_selection \n",
    "from preprocessing import fix_encoding, split_tweet_sentences, tokenize_tweets, get_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and preprocess dataset\n",
    "\n",
    "Load the dataset contaning the tweets and their emotions. For text preprocessing first the tweet text is encoded (fixed), then the tweet is tokenized, and finally the tokens are lematized. The dataset needs to have a column with name tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    class                                             tokens  \\\n",
      "0  1000001  neutral  [[Check, this, video, out, -, -, President, Ob...   \n",
      "1  1000002  neutral  [[need, suggestions, for, a, good, IR, filter,...   \n",
      "2  1000003  neutral  [[@surfit, :, I, just, checked, my, google, fo...   \n",
      "3  1000004  neutral  [[is, in, San, Francisco, at, Bay, to, Breaker...   \n",
      "4  1000005  neutral               [[just, landed, at, San, Francisco]]   \n",
      "5  1000006  neutral  [[San, Francisco, today, .], [Any, suggestions...   \n",
      "6  1000007  neutral  [[On, my, way, to, see, Star, Trek, @, The, Es...   \n",
      "7  1000008  neutral  [[Going, to, see, star, trek, soon, with, my, ...   \n",
      "8  1000009  neutral  [[Bill, Simmons, in, conversation, with, Malco...   \n",
      "9  1000010  neutral    [[playing, with, cURL, and, the, Twitter, API]]   \n",
      "\n",
      "                                              lemmas  \n",
      "0  [[Check, this, video, out, -, -, President, Ob...  \n",
      "1  [[need, suggestion, for, a, good, IR, filter, ...  \n",
      "2  [[@user, :, I, just, check, my, google, for, m...  \n",
      "3  [[be, in, San, Francisco, at, Bay, to, Breaker...  \n",
      "4                 [[just, land, at, San, Francisco]]  \n",
      "5  [[San, Francisco, today, .], [Any, suggestion,...  \n",
      "6  [[On, my, way, to, see, Star, Trek, @, The, Es...  \n",
      "7  [[Going, to, see, star, trek, soon, with, my, ...  \n",
      "8  [[Bill, Simmons, in, conversation, with, Malco...  \n",
      "9       [[play, with, cURL, and, the, Twitter, API]]  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_excel('data/merged_datasets.xlsx')\n",
    "# fix the tweet text\n",
    "dataset = fix_encoding(dataset)\n",
    "# split the tweet text into sentences\n",
    "dataset = split_tweet_sentences(dataset)\n",
    "# tokenize each sentence of the tweets\n",
    "dataset = tokenize_tweets(dataset)\n",
    "# lemmatise the tweets\n",
    "dataset = get_lemmas(dataset)\n",
    "\n",
    "dataset = dataset.drop(['emotion_intensity', 'tweet'], axis=1)\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load lexicon\n",
    "Load the Warriner et al. lexicon and retain valence and arousal dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word  valence  arousal\n",
      "1     aardvark     6.26     2.41\n",
      "2      abalone     5.30     2.65\n",
      "3      abandon     2.84     3.73\n",
      "4  abandonment     2.63     4.95\n",
      "5        abbey     5.85     2.20\n"
     ]
    }
   ],
   "source": [
    "lexicon = pd.read_csv('lexicons/Ratings_Warriner_et_al.csv', usecols=[0, 1, 2, 5], index_col=0)\n",
    "lexicon.columns = ['word', 'valence', 'arousal']\n",
    "print(lexicon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_jar = 'stanford_parser/stanford-parser.jar'\n",
    "path_to_models_jar = 'stanford_parser/stanford-parser-3.9.1-models.jar'\n",
    "valence_shifter = FeatureExtractionContextValenceShifting(path_to_jar, path_to_models_jar, lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    class                                             tokens  \\\n",
      "0  1000001  neutral  [[Check, this, video, out, -, -, President, Ob...   \n",
      "1  1000002  neutral  [[need, suggestions, for, a, good, IR, filter,...   \n",
      "2  1000003  neutral  [[@surfit, :, I, just, checked, my, google, fo...   \n",
      "3  1000004  neutral  [[is, in, San, Francisco, at, Bay, to, Breaker...   \n",
      "4  1000005  neutral               [[just, landed, at, San, Francisco]]   \n",
      "5  1000006  neutral  [[San, Francisco, today, .], [Any, suggestions...   \n",
      "6  1000007  neutral  [[On, my, way, to, see, Star, Trek, @, The, Es...   \n",
      "7  1000008  neutral  [[Going, to, see, star, trek, soon, with, my, ...   \n",
      "8  1000009  neutral  [[Bill, Simmons, in, conversation, with, Malco...   \n",
      "9  1000010  neutral    [[playing, with, cURL, and, the, Twitter, API]]   \n",
      "\n",
      "                                              lemmas  \\\n",
      "0  [[Check, this, video, out, -, -, President, Ob...   \n",
      "1  [[need, suggestion, for, a, good, IR, filter, ...   \n",
      "2  [[@user, :, I, just, check, my, google, for, m...   \n",
      "3  [[be, in, San, Francisco, at, Bay, to, Breaker...   \n",
      "4                 [[just, land, at, San, Francisco]]   \n",
      "5  [[San, Francisco, today, .], [Any, suggestion,...   \n",
      "6  [[On, my, way, to, see, Star, Trek, @, The, Es...   \n",
      "7  [[Going, to, see, star, trek, soon, with, my, ...   \n",
      "8  [[Bill, Simmons, in, conversation, with, Malco...   \n",
      "9       [[play, with, cURL, and, the, Twitter, API]]   \n",
      "\n",
      "                                            valences  \n",
      "0  [[0, 0, 2.1399999999999997, 0, 0, 0, 0.6900000...  \n",
      "1  [[0.9500000000000002, 1.29, 0, 0, 3.3899999999...  \n",
      "2  [[0, 0, 0, 0, 2.05, 0, 0, 0, 0, 0.980000000000...  \n",
      "3     [[1.6799999999999997, 0, 0, 0, 0, 0, 0, 0, 0]]  \n",
      "4                 [[0, 2.1100000000000003, 0, 0, 0]]  \n",
      "5                       [[0, 0, 0, 0], [0, 1.29, 0]]  \n",
      "6  [[0, 0, 1.4100000000000001, 0, 1.7699999999999...  \n",
      "7  [[0, 0, 1.7699999999999996, 2.9699999999999998...  \n",
      "8           [[0, 0, 0, 2.2199999999999998, 0, 0, 0]]  \n",
      "9                         [[3.05, 0, 0, 0, 0, 0, 0]]  \n"
     ]
    }
   ],
   "source": [
    "# set intial valences from lexicon\n",
    "dataset = valence_shifter.get_initial_valences(dataset)\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id    class                                             lemmas  \\\n",
      "0  1000001  neutral  [Check, this, video, out, -, -, President, Oba...   \n",
      "1  1000002  neutral  [need, suggestion, for, a, good, IR, filter, f...   \n",
      "2  1000003  neutral  [@user, :, I, just, check, my, google, for, my...   \n",
      "3  1000004  neutral  [be, in, San, Francisco, at, Bay, to, Breakers...   \n",
      "4  1000005  neutral                   [just, land, at, San, Francisco]   \n",
      "5  1000006  neutral     [San, Francisco, today, ., Any, suggestion, ?]   \n",
      "6  1000007  neutral  [On, my, way, to, see, Star, Trek, @, The, Esq...   \n",
      "7  1000008  neutral  [Going, to, see, star, trek, soon, with, my, d...   \n",
      "8  1000009  neutral  [Bill, Simmons, in, conversation, with, Malcol...   \n",
      "9  1000010  neutral         [play, with, cURL, and, the, Twitter, API]   \n",
      "\n",
      "                                            valences  \n",
      "0  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "1  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "2  [-1.0, -1.0, -1.0, -1.0, 10.0, -1.0, -1.0, -1....  \n",
      "3  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "4  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "5  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "6  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "7  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "8  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "9  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n"
     ]
    }
   ],
   "source": [
    "featured_dataset, vocab = generate_initial_features(dataset)\n",
    "print(featured_dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_selection\n",
      "[('happy', 0.013070030909320362), ('smile', 0.01057974620608353), ('angry', 0.009554506156129681), ('hilarious', 0.009313254163633882), ('bitter', 0.008905144468520258), ('depression', 0.008538926516890795), ('rage', 0.008035108292014218), ('offend', 0.007811266868194009), ('sadness', 0.007451892855713847), ('anger', 0.007440070106215409), ('nervous', 0.007397450499903377), ('sad', 0.007279418311305791), ('revenge', 0.007050725229037773), ('panic', 0.006867959371935231), ('unhappy', 0.006746363371559505), ('cheer', 0.006541960022363224), ('bully', 0.006269300821539021), ('outrage', 0.006076459154610644), ('terror', 0.006031467113356563), ('laughter', 0.005989333044401438), ('terrorism', 0.005978863447635438), ('anxiety', 0.005785289543543587), ('awful', 0.005615627287863572), ('lively', 0.0054229677717405785), ('nightmare', 0.005353371680887192), ('shocking', 0.005081262377614274), ('hilarity', 0.004937975917861861), ('grim', 0.004914686918869022), ('rejoice', 0.004747085707709682), ('horrible', 0.004503158902106115), ('lost', 0.00446981619197015), ('fear', 0.004442612669780648), ('horror', 0.004363474411851996), ('fume', 0.004284382816676425), ('optimism', 0.004257124949447426), ('!', 0.0042245046893735596), ('terrible', 0.004213296824053962), ('joyful', 0.004211588316696458), ('dark', 0.004152876914810663), ('depress', 0.004124959909384147), ('sadly', 0.004103475831942422), ('glee', 0.00400410223937167), ('depressing', 0.003986939927101578), ('.', 0.003983890265253545), ('delight', 0.0039012045423348074), ('fuming', 0.0038501097773502996), ('furious', 0.0038411052962148266), ('gloomy', 0.0037871031324449014), ('amazing', 0.003777554307955462), ('the', 0.003765385202315368), ('be', 0.003744179947028508), ('and', 0.00360827000344622), ('fury', 0.003553282974454975), ('breezy', 0.003517930029160502), ('live.ly', 0.003433826891950666), ('irritate', 0.00338839560065321), ('love', 0.003321148750366923), ('snap', 0.0033200794321767207), ('@user', 0.0032930257350105387), (',', 0.003258659548305351), ('afraid', 0.003251088492303158), ('playful', 0.0032230774358447006), ('elate', 0.003198218700193073), ('hearty', 0.003166029714510435), ('insult', 0.0031597740619574545), ('to', 0.0031144785037267625), ('you', 0.0030896069489096812), ('sober', 0.003075644954180334), ('i', 0.003067406450596987), ('a', 0.0030485276485951855), ('jquery', 0.003009174892936442), ('serious', 0.0029640742065864755), ('joyous', 0.002888034787630937), ('boil', 0.002861608151385648), ('alarm', 0.0028471642724043115), ('of', 0.002784726639609842), ('offended', 0.0027463599675825387), ('sink', 0.002703427666198507), (\"i'm\", 0.0026429070962039037), ('my', 0.0025414690428166007), ('despair', 0.0025400860567444477), ('in', 0.0025102779099455525), ('it', 0.002504535411388364), ('pout', 0.002496932415484372), ('horrific', 0.002491556944442255), ('discourage', 0.0024696766544452225), ('me', 0.002454218550097263), ('for', 0.0024431916447231273), ('?', 0.0024358343040152405), ('mourn', 0.0024088476465608947), ('wrath', 0.0024082933481696677), ('cheerful', 0.0023855255351644816), ('blue', 0.0023661880647119745), ('that', 0.00235107672638548), ('cheery', 0.00234173501428631), ('shake', 0.0023256007518920488), ('rag', 0.002323445822066423), ('burn', 0.002290003584862183), ('rabid', 0.0022456075216924676), ('shy', 0.002216608474868032), ('offense', 0.0022131686078909595), ('dull', 0.00220720365556383), ('but', 0.0021650563023169426), ('museum', 0.002126617621500317), ('so', 0.0021078601113781277), ('dread', 0.002101984902407429), ('bright', 0.002083535965251944), ('have', 0.002056258132287405), ('just', 0.0019819971413501426), ('on', 0.0019717144756212363), ('go', 0.0019582922351005843), ('threaten', 0.0019368044858106414), ('exhilarate', 0.0018993133451992313), ('musically', 0.0018860462496257102), ('do', 0.0018738620447408302), ('stay', 0.0018222891906912904), ('dreadful', 0.0018053693526867357), ('at', 0.0017971167135665187), ('madden', 0.0017907528346228902), ('relentless', 0.0017866239640696563), ('not', 0.001765492648360447), ('get', 0.0017634446689944426), ('worry', 0.0017607286293026864), ('with', 0.0017327506385759917), ('resent', 0.001723391132111079), ('weary', 0.0017179644124544822), ('safeway', 0.001661333277203799), ('shock', 0.0016387186088068074), ('sting', 0.001634900181002178), ('will', 0.0016334797532628238), ('gloom', 0.0016252569498737724), ('an', 0.0016223032178230051), ('cheerfully', 0.00161031318738944), ('this', 0.0016063699320445074), ('restless', 0.0015993043026246048), ('fiery', 0.0015960147637931886), ('people', 0.0015896416298760846), ('up', 0.0015541878180991813), ('good', 0.0015199987987425387), ('lose', 0.0015183419905325925), ('like', 0.001491407658913385), (\"'\", 0.0014835244631988096), ('your', 0.0014708362142151622), ('if', 0.0014645340502469563), ('no', 0.0014625081914003914), ('what', 0.0014452834256620506), ('burst', 0.001443351036379185), ('know', 0.0014209903821176175), (':', 0.001392379378977115), ('we', 0.0013866934717616892), ('concern', 0.0013866103433531588), ('when', 0.0013854389278646977), ('about', 0.0013816548227889996), (\"it's\", 0.001368278911146216), ('now', 0.0013626455105370176), ('-', 0.0013618960231697673), ('watch', 0.0013508636952580114), ('too', 0.0013470060709823185), ('smiling', 0.0013265329711950379), ('dismal', 0.0012948095966705537), ('day', 0.0012906138762035185), ('chirp', 0.001281770010873848), ('huff', 0.0012551174098036602), ('heyday', 0.0012510073390216106), ('grudge', 0.001225755899666242), ('sunk', 0.0012224901391905277), ('as', 0.0012203283844102754), ('scare', 0.0012130162934345192), ('birthday', 0.0012084317296665553), ('exhilaration', 0.001204441590211942), ('nike', 0.0012038540673613193), (\"don't\", 0.001198925642977974), ('please', 0.001196288639416365), ('sulk', 0.0011961431713548546), ('some', 0.0011958099414395784), ('make', 0.0011906678480880146), ('out', 0.001181559069963092), ('they', 0.001174971542132633), ('‚ù§', 0.0011738928910757116), ('how', 0.0011650692012968801), ('why', 0.0011602123598418216), (\"can't\", 0.0011461516876057109), ('frown', 0.0011286365832120933), ('levity', 0.0011237937855201534), ('pakistan', 0.0011210811635870978), ('api', 0.0011202638787298012), ('he', 0.0011183924581846748), ('think', 0.0011163574952481694), ('infuriate', 0.0011030981150481178), ('can', 0.0011020514483621546), ('one', 0.0010983299968666462), ('or', 0.001086418166611688), ('all', 0.0010833170767236336), ('wonderful', 0.0010799598761822324), ('say', 0.0010679581545060563), ('&', 0.001066149907118906), ('from', 0.0010600181691035584), ('life', 0.0010586528717789392), ('fuck', 0.0010446996999804114), ('eat', 0.001043240287851085), ('..', 0.001042365645418356), ('pine', 0.0010356083681407574), ('horrid', 0.001021331324843747), ('lol', 0.0010112619709958589), ('china', 0.0009958306620002758), ('attack', 0.0009811204545290301), ('beautiful', 0.0009788974839842163), ('provoke', 0.0009772377365143664), ('pessimist', 0.0009771558095781625), ('resentment', 0.000950164528359131), ('feel', 0.0009484787311804368), ('always', 0.0009447798884211484), ('there', 0.0009358283566413405), ('melancholy', 0.0009343675346402307), ('then', 0.0009153821777830832), ('haunt', 0.0009116229611256799), ('hard', 0.000911397078655952), ('baseball', 0.0008971503592305315), ('animated', 0.0008966856502622972), ('them', 0.0008965972224474125), ('want', 0.0008912725661451525), ('who', 0.0008875648457213955), ('over', 0.0008814587708838278), ('talk', 0.000876311821773923), ('still', 0.0008742695257395137), ('give', 0.0008700156626272109), ('look', 0.000869203694061652), ('work', 0.0008611137572411611), ('well', 0.0008525416855402047), ('off', 0.0008502181759077146), ('would', 0.0008500490128673408), ('new', 0.0008482476071878673), ('even', 0.0008446513219275669), ('francisco', 0.0008445163385232957), ('more', 0.0008427226634893073), ('victory', 0.0008419646473654344), ('bad', 0.0008386476406363755), ('trump', 0.0008335421227613322), ('cheering', 0.0008325338249729579), ('stanford', 0.0008325149790792373), ('way', 0.0008230311220456492), ('today', 0.0008201279051045036), ('country', 0.0008199106795309318), ('time', 0.0008190319730250074), ('mirth', 0.0008183354273084642), ('his', 0.0008151154441197407), ('see', 0.000807514015002418), ('her', 0.0008059757575476091), ('play', 0.0008034432296375163), ('him', 0.0007891477019322795), ('accept', 0.000785049720758551), ('start', 0.0007730418864136305), ('again', 0.0007702448818582223), ('oh', 0.000768687687113779), ('take', 0.0007682860772071929), ('she', 0.0007669150165317618), ('gm', 0.0007666180101081675), ('last', 0.0007546779699631734), ('need', 0.000753647610716943), ('kill', 0.0007527650807456958), ('sparkling', 0.0007522388530234044), ('should', 0.0007520615440070107), ('exhilarating', 0.000737794169285493), ('hold', 0.0007350399864559057), ('by', 0.0007347546129726335), ('back', 0.0007333589893568982), ('thing', 0.0007282212488512318), ('much', 0.0007277034078379511), ('because', 0.0007254780238198169), ('irritation', 0.000720910910338318), ('only', 0.0007181717808597705), ('üòÇ', 0.0007181452130470001), ('india', 0.0007152608703561966), ('tell', 0.0007127933648772248), ('little', 0.0007077223962258409), ('dash', 0.0007074550345067263), ('jovial', 0.0007062808879199873), ('stop', 0.0007032093893567958), ('best', 0.0007008726747623567), ('black', 0.0006991885997081132), ('right', 0.00069501016968791), ('really', 0.0006889180381132401), ('thank', 0.0006882530630120114), ('any', 0.0006872400347765625), ('end', 0.000681631368913205), ('cheerfulness', 0.0006732054306330425), ('could', 0.000663401381135034), ('(', 0.000659978041097314), ('gleeful', 0.0006597606142380001), ('quote', 0.0006551347555685553), ('laugh', 0.0006544133129424558), ('üò§', 0.0006528830949870618), ('sparkle', 0.0006523367100127687), ('twitter', 0.0006484174541515104), ('blog', 0.0006395907341191366), ('shudder', 0.0006368484283284188), (')', 0.0006308266810125373), ('juggle', 0.0006299735500238518), ('fret', 0.0006274457824169352), ('leave', 0.0006243856646236349), ('grieve', 0.0006216650626090579), ('night', 0.000620768236663119), ('show', 0.0006161430619536987), ('heart', 0.000612774324286226), ('man', 0.000610031060160173), ('burning', 0.0006083881645043074), ('come', 0.0006049395210336522), ('through', 0.0006041464388750966), ('n', 0.0006024477950637834), ('try', 0.0006000321178630654), ('great', 0.0005965088251018052), ('thanks', 0.0005887334048304642), ('police', 0.0005830296005190965), ('here', 0.0005747527296765173), ('2', 0.0005710490249336231), ('funny', 0.0005707373918814047), ('call', 0.0005674105378993322), ('after', 0.0005673430493137964), ('tiff', 0.0005632543357963013), ('someone', 0.0005612953600998017), (\"that's\", 0.0005604091658274787), ('our', 0.0005595788330282566), ('let', 0.0005570646621896185), ('animate', 0.0005545441993353947), ('into', 0.0005522843177897033), ('/', 0.0005494845354699145), ('ever', 0.0005475917614626147), ('cause', 0.0005458201542674879), ('*', 0.0005446565833413532), ('meet', 0.0005396914479199351), ('use', 0.0005393859594158667), ('god', 0.0005357806654416979), ('face', 0.0005343341282640148), ('aesthetically', 0.0005318970766667248), (':)', 0.0005310619368930288), ('die', 0.0005306976441965393), ('same', 0.0005287653610799787), ('most', 0.0005285632321148671), ('keep', 0.00052620044859198), ('without', 0.0005210696410000015), ('shiver', 0.0005204336295858045), (' ', 0.000520183332951188), ('Ô∏è', 0.0005181057044850835), ('shit', 0.0005171258185818455), ('friend', 0.00051559233584453), ('down', 0.0005094808374476783), ('find', 0.0005088466896793557), ('dentist', 0.000507562789065745), (\"didn't\", 0.0005069615129846314), ('happiness', 0.0005042456104955517), ('change', 0.0004996888568522264), ('turn', 0.0004992431842217669), ('hate', 0.0004971737262598606), ('yeah', 0.0004960659697258004), ('next', 0.0004921319348552912), ('soon', 0.0004851346483695631), ('old', 0.0004838297431302277), ('never', 0.0004818261078809202), ('first', 0.0004805184194738456), ('such', 0.00047763386414362096), ('fucking', 0.0004769075420321822), ('actually', 0.0004761117361511685), ('something', 0.00047567463624187834), ('dream', 0.0004751512219669881), ('provocation', 0.00047324008991208417), ('üòç', 0.000469516308825296), ('white', 0.00046921150843014567), ('irate', 0.0004672880543208317), ('those', 0.0004636888105004868), ('their', 0.0004634688955678817), ('side', 0.00046220685472485746), ('ugh', 0.00045994936209167107), ('mean', 0.00045836855519135346), ('than', 0.00045683915766250453), ('another', 0.0004547614545329099), ('üò©', 0.0004459787991766098), ('tonight', 0.00044482333576123366), ('im', 0.000443411788396301), ('anything', 0.00044011616022787795), ('where', 0.0004393784981628547), ('u', 0.0004387125279863858), ('tomorrow', 0.00043857842870767734), ('hope', 0.00043801184642489256), ('year', 0.0004367098487935509), ('bc', 0.00043452698143783277), ('test', 0.00043329740013646706), ('post', 0.00042819150707359207), ('lie', 0.00042811144751294967), ('rt', 0.00042786600882876844), ('wanna', 0.00042717098855149115), ('eating', 0.00042393063275689526), ('every', 0.0004235160321420994), ('5', 0.00042298703877040366), ('before', 0.00042179202178386246), ('episode', 0.00042056547937824215), ('very', 0.00041926935496273634), ('pay', 0.00041825216931751013), ('sure', 0.00041501916987896347), ('guy', 0.0004140232391178824), ('affliction', 0.0004126450003772781), ('head', 0.0004103973983252125), (\"i've\", 0.0004076773155525943), ('hell', 0.0004060793268401474), ('hey', 0.00039745240311686304), ('least', 0.00039736187592448447), ('deject', 0.0003943795134915759), ('joke', 0.0003918392719244585), ('aggravate', 0.0003888115884264641), ('mhchat', 0.0003876539522983785), ('morning', 0.00038699833224869427), ('lot', 0.00038367944789301125), ('its', 0.0003826321921910844), ('intimidation', 0.0003824727675255359), ('phone', 0.000380763979851793), ('both', 0.00037998985420358423), ('yet', 0.00037971759206173407), ('unga', 0.0003761505240938315), ('google', 0.00037461602358689934), ('pick', 0.00037373493096957316), ('mind', 0.00037285662844242394), ('world', 0.00037111238889770326), ('scary', 0.00037042978583563796), ('since', 0.0003703098780251333), ('month', 0.0003697679613416305), ('mope', 0.00036967268021095953), ('tweet', 0.00036857275068429604), ('nothing', 0.00036730989619931676), ('dinner', 0.00036662412611721527), ('live', 0.0003662500615808151), ('literally', 0.0003638947767399909), ('animosity', 0.0003619355471469807), ('follow', 0.0003601978867532792), ('put', 0.00035770358160544676), ('person', 0.00035650198206621747), ('bb18', 0.00035644939261148353), ('grateful', 0.00035522868762745955), ('boiling', 0.000354445201171667), ('win', 0.0003530851993542532), ('house', 0.00035223056022515065), ('intimidate', 0.00035076765269050406), ('san', 0.0003500358957333168), ('maybe', 0.00034948617586646216), ('sometimes', 0.0003487041373350752), ('disabled', 0.0003482144201626726), ('move', 0.0003479932989975035), ('tantrum', 0.00034771681128496117), ('week', 0.0003470978780843309), (\"we're\", 0.00034704371018442646), ('sleep', 0.00034529127886218596), ('despondent', 0.00034411690766736303), ('team', 0.00034290686103924807), ('hour', 0.00034089386594860665), ('blood', 0.00034055863653582885), ('against', 0.000340389140702677), ('tired', 0.000340089708222334), ('write', 0.0003398181434711047), ('either', 0.00033725951826229193), ('future', 0.000336396405641198), ('movie', 0.0003358172701667382), ('üò≠', 0.00033570316492715133), ('awe', 0.0003346329744758794), ('us', 0.000333396786234275), ('later', 0.0003332141322259964), ('incense', 0.00033255399699075257), ('okay', 0.0003325242872501321), ('problem', 0.0003318083901008918), (\"i'll\", 0.00033166347389406223), ('must', 0.0003309304047460309), ('once', 0.0003305655329851777), ('forget', 0.0003299010354433991), ('top', 0.0003289621185870712), ('big', 0.0003272469305781141), ('1', 0.00032500772681476954), ('inside', 0.0003237887148962947), ('around', 0.00032295458045169124), (\"doesn't\", 0.00031935486782455066), ('sorry', 0.00031892718005837835), ('book', 0.00031558590102303565), ('help', 0.00031539808904943367), ('20', 0.0003144486477599906), ('these', 0.0003139080848863114), ('cop', 0.000313298229360052), ('‚ò∫', 0.0003131766390217459), ('marketing', 0.00031152872591282734), ('scar', 0.00031098868447161025), ('break', 0.0003109651021929318), ('feeling', 0.0003109587646879358), ('alone', 0.00030930963041968533), ('everyone', 0.0003083528853991161), ('nose', 0.00030735886234348924), ('seriously', 0.00030694178680639166), ('dude', 0.00030670691841305813), ('üôÑ', 0.0003066295894230079), ('service', 0.0003051749609337893), ('bring', 0.00030362155829492826), ('michelle', 0.00030351224723773097), ('shaking', 0.0003031992704057747), ('raging', 0.0003030229915521441), ('word', 0.0003028215157787583), ('pretty', 0.000301852687589142), ('wake', 0.00030021525552480254)]\n"
     ]
    }
   ],
   "source": [
    "X = featured_dataset['valences'].values.tolist()\n",
    "y = featured_dataset['class'].values\n",
    "y[y == 'neutral'] = 'n'\n",
    "y[y == 'fear'] = 'f'\n",
    "y[y == 'anger'] = 'a'\n",
    "y[y == 'sadness'] = 's'\n",
    "y[y == 'joy'] = 'j'\n",
    "selected, mask = feature_selection(X, y, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id class                                             lemmas  \\\n",
      "0  1000001     n  [Check, this, video, out, -, -, President, Oba...   \n",
      "1  1000002     n  [need, suggestion, for, a, good, IR, filter, f...   \n",
      "2  1000003     n  [@user, :, I, just, check, my, google, for, my...   \n",
      "3  1000004     n  [be, in, San, Francisco, at, Bay, to, Breakers...   \n",
      "4  1000005     n                   [just, land, at, San, Francisco]   \n",
      "5  1000006     n     [San, Francisco, today, ., Any, suggestion, ?]   \n",
      "6  1000007     n  [On, my, way, to, see, Star, Trek, @, The, Esq...   \n",
      "7  1000008     n  [Going, to, see, star, trek, soon, with, my, d...   \n",
      "8  1000009     n  [Bill, Simmons, in, conversation, with, Malcol...   \n",
      "9  1000010     n         [play, with, cURL, and, the, Twitter, API]   \n",
      "\n",
      "                                            valences  \n",
      "0  [-1.0, -1.0, -1.0, 10.0, -1.0, -1.0, -1.0, -1....  \n",
      "1  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "2  [-1.0, 10.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "3  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "4  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "5  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "6  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "7  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "8  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
      "9  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n"
     ]
    }
   ],
   "source": [
    "for index, row in featured_dataset.iterrows():\n",
    "    valences = np.array(row.valences[mask])\n",
    "    featured_dataset.set_value(index=index, col='valences', value=valences)\n",
    "print(featured_dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5348, 501)\n",
      "   v_0   v_1  v_2   v_3  v_4  v_5  v_6  v_7   v_8   v_9   ...     v_492  \\\n",
      "0 -1.0  -1.0 -1.0  10.0 -1.0 -1.0 -1.0 -1.0  10.0  -1.0   ...      -1.0   \n",
      "1 -1.0  -1.0 -1.0  -1.0 -1.0 -1.0 -1.0 -1.0  -1.0  10.0   ...      -1.0   \n",
      "2 -1.0  10.0 -1.0  -1.0 -1.0 -1.0 -1.0 -1.0  10.0  10.0   ...      -1.0   \n",
      "3 -1.0  -1.0 -1.0  -1.0 -1.0 -1.0 -1.0 -1.0  -1.0  10.0   ...      -1.0   \n",
      "4 -1.0  -1.0 -1.0  -1.0 -1.0 -1.0 -1.0 -1.0  -1.0  -1.0   ...      -1.0   \n",
      "\n",
      "   v_493  v_494  v_495  v_496  v_497  v_498  v_499  v_500  emotion  \n",
      "0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0        n  \n",
      "1   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0        n  \n",
      "2   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0        n  \n",
      "3   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0        n  \n",
      "4   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0   -1.0        n  \n",
      "\n",
      "[5 rows x 502 columns]\n"
     ]
    }
   ],
   "source": [
    "temp = pd.DataFrame(np.vstack(featured_dataset.valences.values))\n",
    "print(np.vstack(featured_dataset.valences.values).shape)\n",
    "temp.columns = ['v_' + str(i) for i in range(len(selected))]\n",
    "temp['emotion'] = featured_dataset['class'].values\n",
    "print(temp.head(5))\n",
    "temp.to_csv('data_final/features_emotion_detection.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
